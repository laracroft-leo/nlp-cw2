{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2312,
     "status": "ok",
     "timestamp": 1743751954039,
     "user": {
      "displayName": "yu Wu",
      "userId": "12692660435918028293"
     },
     "user_tz": -60
    },
    "id": "CrfO4qeKtgek",
    "outputId": "24506c3e-e6d6-4a62-d0a4-68958472609d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub[hf_xet] in /usr/local/lib/python3.11/dist-packages (0.30.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (4.13.0)\n",
      "Requirement already satisfied: hf-xet>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub[hf_xet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2109,
     "status": "ok",
     "timestamp": 1743751956150,
     "user": {
      "displayName": "yu Wu",
      "userId": "12692660435918028293"
     },
     "user_tz": -60
    },
    "id": "VpSbJ-Qytrql",
    "outputId": "99009a9d-1752-4ed5-91e0-c438bf6f313c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji==0.6.0 in /usr/local/lib/python3.11/dist-packages (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install emoji==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "01770e86bc4e4bacb15efaafc978cc21",
      "849964bf776b4202a040629fe0c24503",
      "3e40ec7ac76d4eaaaa5a1e2729e48a7f",
      "ae0cfe2b3c9d48fa8b31f7287aa43697",
      "86ff9e3db2754e56aac498f8170c8834",
      "b138aae7bec04a80a785549afb14bf70",
      "1554eed9a6b74053bd39b109cf7da38a",
      "fb283ee8a1b14f5f92db501a429fe126",
      "1436da796b6d48c4a8ae47c626290448",
      "a30dabd2365a4866b1466ab5c4224728",
      "993cf09a167542e3a86ddab4a90c54a5",
      "95a594eaeb5d47adae05d42c281e5d1c",
      "cafe3f0d669049a496168bc2309a1e0c",
      "b75226a3517e441bb77ae84bb87b283d",
      "094d0993c8084581a2dedca5e7fce0e1",
      "d1fa908893d24bf483675775a541c040",
      "bc4125a9d1364bdeb912a537d13bcda2",
      "4288c86f4a0f4c20ac6c11e34178fb2c",
      "2f82ae343b43453294660e516dab6f69",
      "26b35cf6fbe444d2a0c614b0d4a46eb3",
      "4d1a8315e2b84f539e765b6a0bcc4d9d",
      "c5615a1b78dc444f9be85910fac6399d",
      "cadcc09789024ccc933770105277cf38",
      "8ead43ac30e040ad9b23ff2da45fc000",
      "1f3f63a3381c41028d6f0fb0b2162f6a",
      "336a7d4068e04634b61d82b8c2ce63da",
      "3f5d24d99b864cfe9eafdc611bed43e0",
      "4878518b91ca4329bbc2fe32bcd76557",
      "9356c82cc4fe47ccb7712ce545515c21",
      "0643ebb9a7cc48989aee1907a115bd92",
      "220606c911f24c41b1bbd44904cfa872",
      "33873f3d5a4f45129d88d70ef21fd356",
      "9cc94dc535c648c3a5e5a62e57a342f5",
      "56b1ebaa8096430a907a7befae899550",
      "38d2ee0d2db34299ba0ab836f12bc1f9",
      "4005189626c54c30bb1cf819330aca27",
      "206f03872b484d06b975eb3c7ec9b7c4",
      "414883b903e4408aa12438d5ae2e2daa",
      "71012618e3f74fbca81b477b50dd8740",
      "3868507886204cfdbcbb24e9ccb676a3",
      "3a8398fba01b4bd79b9bf9dabe3ce690",
      "ada4ae5294124cafab7339a0c44ae16b",
      "b97dff7e712b49f2b5f2b0a7ca727b6e",
      "bc2f4bff86764679a1c047c08136fff7",
      "746142a0a07243499ce94b6a751a3df1",
      "b688b33f2cd44e188359fd0ccfbf3834",
      "0b572ebbd18549e2bb0298d1a9488c96",
      "ce4f6c9e3567401e874879103d785614",
      "93bd0f3af6c94e139b7d95f9c1ee86c7",
      "322668c66cff4b11bece6d5ccc8eef84",
      "9e87f5ec9b144c1db51323573149db99",
      "556857c7581b43c8b094ff77f8772e2a",
      "3543d7a5729244aba605cee24a7739ec",
      "7289d4e357db4b5d91fc29874896a202",
      "3aaf90828e35481bbae54cd3f53c1c1d",
      "73103fb64ffe47e4897f4769b9617aad",
      "b586ae7791e24b5189e8967e119f012f",
      "2714452d301f48958f6f5e62a44382f5",
      "f2f99c9cab9b46f988a3d6c334b38ae9",
      "8a94128421094d06ad8bbd084f6869ba",
      "adba00640d3c43fd80029d4181b96629",
      "37ac23a17cc44c6d84a14e0611cacc81",
      "86cfc4071f6a459a8e43c87d5d829f10",
      "31ada4766a94491e9c06e7de517e271e",
      "2227bd5e4acf49eb9a0668897d8a6e47",
      "dc183ae1d3a84cfdbfa77d67ab97899b",
      "11797871578f48a587d81b52846301e2",
      "acfb03b429f543958c23cae8069be119",
      "61572ce7170649199d6a4e5a712b8649",
      "66409fbd979e4e2bbee121caf97cf1c3",
      "7c49c8187ac24cdd894956a127836448",
      "60e64c03f7314c0babc30472f7f7deaf",
      "922588e7422d4c75958c1b9a63c4a246",
      "d7da0b5d0dea415b8955bd47a799ab1c",
      "2f4bd65dd4e9474ca731614dd82652ec",
      "d31bae3e061f43c0992e34625d468d74",
      "0f5619ecede54b38904dd14c3d6aaf01",
      "40e8069ad4584130bb9964966f7ddb00",
      "fbfb7bf1182640d18eb7b5e8cdda4b29",
      "0864278d668b41f495e427632ec9de41",
      "0c1a3bbf07ab4a8ba9f997bffc7a3b58",
      "de7e445df1e648a8b4493c2065b02501",
      "30e009a2b60e4ad48d2fea2bcf5aa110",
      "4b5778f2b5d9412394b503e33a6171d1",
      "e961ab3f850945828b6bd4a2cc8e43b1",
      "77b536c5232b479fa63eefa6265b665d",
      "8c45e76b330343899347f3034ce08c59",
      "47e83be1956e4db192a6ddc0a7119626",
      "559c6c0ef96c4eb990e022e6dec7d42e",
      "dba9a6469b104e3790b5bd6aae3981cf",
      "78433516d48c4d47b6a167ae259c4797",
      "4d36e05f20644b6b8581b32dd6194fb0",
      "435293490a2e45f1944a453bdb116bdf",
      "d31e89ee553247c08993aa22acaac3fe",
      "76c7eba26ba14d5f96f8e321c6e122e4",
      "8069cbd8d39441768f1326e19dbca897",
      "e4a240c7afcc4fcb89b507f7b51b42a4",
      "6f612c86a013477985ffc01dce7c980c",
      "beb72d1412584bf89e2665635dad3a83",
      "154142b376cb4463b9f1503f021267da",
      "48e6e989f0064ee2a98b9381b26e51d1",
      "8af17db2063544ee9ac9674cba40d4cb",
      "f1963ba524384d0c85caaeba074c4d5c",
      "4e70f1c5c8ae473b933a73693168ff35",
      "cfc5f952de3a4da3a0d828e6e241b0e1",
      "42f5c275adb6421090e2cc3964379f2f",
      "c27d3ee89f06490d9c3e6d1fa1ea0b32",
      "b790f8a8aaac49b5a52036d02f4f73c3",
      "acc6bd37e70945008aabf7d3d34ed580",
      "1eaa84d929ab42cf94f09b9ffacb8179",
      "244e1b284c2c4a15af92c2b8f4649364",
      "5de4ee29d0be4ce69e1aa9cbfb3c334d",
      "7c9c028231224b689223f1095ab0d228",
      "16a24df8e38947dbb2144bcd57c913a1",
      "1a1f0bfce86c4a8886d0cbfd64e076b2",
      "206eb01aa8b84b1f951bb66eafa19bb7",
      "d88d298fc8ee4d4ea62c4143480414ef",
      "2fe5fd88adcf4d3b8847194313650999",
      "1bff257b2e544dbcabb6da5d7e55acea",
      "b5c743b9fc5548a3ace3f2de2f406e56",
      "963f1515fc7b425891fbc5e22a44860a",
      "ff1d8c447b5f43a292e14f19d4a05469",
      "daff3c24daed4638ab37560aaf712e7b",
      "5ceb44a08bf744058905d0a387d0e67d",
      "219a09c9edbb4b50a44559769bab9d30",
      "9075668428e94ffdb29500df12a484c8",
      "0391bad5008d4a109a191b4a84bf3eee",
      "a02be800fbb44b3580615779804e7a76",
      "635939fca88048aba92ef5663e9dcb37",
      "063fa38f1d1042e2ad37343b02aa15cc",
      "7210d4f9d3eb4442be757a8347ffa349",
      "e2328e0ddf7a44f4a174a1058cee2c13",
      "286b0bd95e25451aae808b734377de63",
      "8c70dc902f054f9088e73a9f61ca926e",
      "09976845304d4749959206a47f92a522",
      "05e40a490e4b47b7a5a16285a3dda8ff",
      "b3d13cd13e1344d3b911fc028bf086c1",
      "4c348f1a95f0473d96db5961e0f6cd46",
      "1c28138159d04fda8d0023c5ee6a0b33",
      "0b3dd5e9ab7444169a41c7ecb6c99607",
      "2fb456c1a87b4386afe63880f0dc4032",
      "ac202bf45bb14f8fabe35781a9cacd78",
      "b6a5a9f84297420986271dcbfcf7de75",
      "86e5772334ac42b09f47511c7197003e",
      "76dfe25dd7304e70af32f6b39bf5546e",
      "9b9e8f83327444c6b0387d85bccf90da",
      "e52e46130b29469bae7f6ed2ef6a97a0",
      "25e726c8799b4878bf77d288e2e6ca37",
      "59409f2be42e4d289a5f3cad4213108b",
      "ffab92ab14bb4620b2628fb6fce813aa",
      "d094c4a867a64bf795997e367f7e726c",
      "45b86de665ac485383b186428d8b7e2f",
      "7ff3b3d0e8db42cd8627a467297c42be",
      "22a6f820f5394b78b5b605131845c3f0",
      "10fd91c206114b10b531f9989bc742a8",
      "a45e714ec1364968a817c0e9f3f8b85e",
      "1e86faa916fc42b6bd6eb35cf439eaac",
      "de8df60fe9304feabd6489b60ce40b93",
      "882425bc378b48aa85b636304f4dd063",
      "57baec84a4d64f528051cce04b7dd7e4",
      "25b7d192076e40c980262d91ec63dba1",
      "7264a197c1914707ac8b4b141454e3fc",
      "f98bd1efd5be48e6bf03d68c5ef7fb8f",
      "f8eed28da585484b9489f4497cccd1ea",
      "298799f724ee458b9e8e30045ba14bc2",
      "16d90799ee274fd8a831afcda9a990ac",
      "2ca2361842b34e0599ba1e37fd964ac5",
      "b0cbe0026c834b64b068d0df9cadd16f",
      "72b3b1a90b5846b882d701a4e8b7b295",
      "3881497973d94b8e8ec37cb91f791609",
      "bbe22bb5996d4c44b9c7c880986eaa99",
      "13274dced0d4438992c49eb22fadf381",
      "d01d4547fa2b425393116ee1918ecde0",
      "69f2243fce2a4b2b92c8f93f444b4b3a",
      "bdcba775e1264d4f9290cdfb37e097c8",
      "226c386038a94a1b8eb61a4a217945e3",
      "9d005fe1d3ed43edad5a23ed14331352",
      "04f09f54afdf4286951519c42d94eccb",
      "ec15c0133f96499d825d1b847b8cbbe8",
      "9a912a9f84a84da8bcd7eb2d6cf8562d",
      "352aeb76a33d41ef8fd7e41af2a080dd",
      "89235572ba0f461290c0acb2801ba0b4",
      "0c2945cadac24457889267733f9613ae",
      "8f05451e6cd04095934f385be1e5e564",
      "7a4347296bf34b4ea91ce926ed6e68fc",
      "caa970a7502e40c39dd07cbbeaa255cc",
      "6bcb75f4f2a84eefa385a35373dd2ac5",
      "1c42c86ec8fe4e498440f39b3bd9d4e1",
      "453511987c9048ea93e8705364e1e59e",
      "9ed92b2e247d4f018b00e61ec278c7f7",
      "262473fefa744c43bf52d5e8b2ae7b21",
      "1f197d33a5da4796b21a226b4573bf4a",
      "83fbe6d4d98d457290e067fb1d7cb605",
      "88e30c4041244e039433005899ad422f",
      "f29b0e90508f4d299ea0b35932825bf4",
      "9771f99b8ded49689e8c2ad083f0f2b0",
      "31e41d6a566f4c309e080743b8bef56c",
      "4eed22c8296e4783a2485594f69343b8",
      "2164c1434ec54c908d2b6287287616a7",
      "c94ebff713dc46b0887c6fc23764bf5b",
      "c4c71388af054fb4a73a2c574c2fbfb4",
      "2853c4cbd0524d39b8c47167fccc02df",
      "8c81ec0e980743c98bcbb26905f91a50",
      "2f334b14c5004968a121e0300a552b24",
      "9f57a8764b9c432995b73fb5d178df36",
      "a4a1835766254343a24bf401fd94bdf1",
      "0bbb7daed2bf4b54970aa07b88d34306",
      "96da4fd3d3464e48850e91457f4f3a8d",
      "ecf990cb15c846a28709e6464d50902e",
      "37ce430b51434c0f8958697b3bd944f6",
      "cf938ade12a0434db03096c433f04572",
      "6cfd155bcf994b638659f0610b50ae9d",
      "3fef6cb40cdc497c9142c56f91f188bf",
      "c9d169e3de4b4a1b8877d0add9e7fb2f",
      "9eb9919302c444f2aa3d0bfe1f45df3d",
      "0473a17d9218442c8719f673e6cc5ec8",
      "9befb350749a469bac49c1619e19416d",
      "b252e6ac78a546f3a52dae615c488c1c",
      "fbab2734709b427ea7b94cb0389f9fb9",
      "fcfc65d4a1ee465f9e6cdf08225d23f3",
      "41dff0dea714422eaba36e8bab860b4f",
      "ab724f583c844272afae04b3192ea9bb",
      "e20e239d0c7545e8995de75fcc90ae63",
      "fd9b324c44ba41e390540d5075469ba7",
      "50f84a654ca8451784d7fe589119cc59",
      "0e8716c625e64122bb5d72eb0bd7d3cc",
      "3173a949b064415799e7ca93391c353d",
      "a60f5330f62346299c07ff6763d2ea3c",
      "f2ef2092eac847b0856a63c329926f8d",
      "dc55056d43f24de1b198d1fb26c89b53",
      "913350fea61a4ee49d00a7dd9af1e4b2",
      "cf710c17590940c781229eccfd68c9dd",
      "5028899a6671448d82d12ab2dc21b2af",
      "871739d7af9545f3b29ea6df3c360df6",
      "67e2f11d32be410abb838b10c24a74d7",
      "c2e2f94f42fe4c9f97a7cec025ff79fd",
      "5d275110b7ce4efb916d40d52bf8ae01",
      "d5062304104f47e88469e3d584a2b790",
      "1bd3b65e11b94177836f4f41155e0521",
      "0cda68edf97b4508bfec943b91496fd6",
      "5c6c8ea73e39468d8447ff6aaa4bb6b8",
      "38964e98caf74b869cb759aa5cc873e7",
      "0ef7214b441444b9b72ed4ab2358d638",
      "c4bb29c3f89644a89716322e131575ee",
      "ac70c128a9e24ee889f15bfe8ecbbe67",
      "dbb3c1c0e927455a8cd80e4113636939",
      "974e7d5bd0a0493f9b13fccea4c717f6",
      "951c0ae02a15472280b9ac1319e08265",
      "a341d01a7f414c1aad9c98e956955db9",
      "2c50169961b4477a9d9fbc11f6b5e725",
      "e944fc64dc764a1899d7d3f616a323ec",
      "ec1e7b9cadbb4870932f025530d3af4b",
      "c2c7763f997d42ae81032d0a0cc1620b",
      "441e97450f59438ab04d410c34994b04",
      "98f74b693ae4465cb194355a4d2fbff5",
      "b1be77eb2fef424cb0cfb3288a81671a",
      "cf56549517d2469694ee3dff4e92e514",
      "1e3cd750e01847e29c25f01e25e84dc4",
      "22de7f36213842d5bf7064b7e744c267",
      "d2e2b1d436e948d0aea4a7ccab2d624a",
      "3b22488cc08d4de5879cc36c98dc4c96",
      "499683a02a8740c2bb3c3664661974a4",
      "c14f0b41b7c64a99809f97c488b73ce6",
      "4eaa4341128c4e859d1824b26fe68774",
      "9ae46f9606454cb0a1600d73000f047b",
      "b418d7dfb8aa41b0ba3b6ceb80240af5",
      "86a4d80cc251496da60e1e1b1230c00f",
      "5dfb20da361c40858419c64e3cf1995e",
      "40f5946d33b1402fa9ef2317d91af0c4",
      "5b8422f4f45e4d1e87b49450557b1fb3",
      "573eac1addd04ad6931d43d4077d0b4a",
      "0c7abb2b44e74f41bfaee10620a2a3a8",
      "6023c3c3b0864583879ee5828c87d5ff",
      "96f0232c90b2444c88051aed3f77aa40",
      "09b696a991b748eab9616e726cd50da2",
      "8174b0f99efe4e9dbc551a41d5bbcb56",
      "eecde8f161a8462bb8ad1236664234a3",
      "105bc8c6664b4a529a89a0406ed7fe52",
      "b8a465da3980485995c313e948c632e9",
      "8b80a268ec1a4d0c8823d092566a8f78",
      "9da99e8eb764456792dc8c95035903e8",
      "70dbabc029e04ca3a46544a57d6d60ec",
      "7e5294f1547e4a29b50bcf2f36bce3ab",
      "a1784c5495be48caaa6730e28e4880ba",
      "c67cdbd88c9645bdaef1f0fb8aa5063b",
      "984aa902f6e3443e8ecdb3547eb126be",
      "d97ec685d7694283b299ce25334c3164",
      "8b6cb11dac55455199b113f364d0dca3",
      "f47a61d27bdf4bc692dcb5ce1cd88f39",
      "b834672808024fc1821a13818a544d7e",
      "d9bba0f8dbbe4361822f4cd140a2fd29",
      "34b1c97834a04038b7b59b01515692e4",
      "685d071a191843348f6af21197ce0b15",
      "b74a5f8462064ce1b970fb9ad2203fbf",
      "c7fd9afec74047a5a147e15da05f80ea",
      "8a40e9c1346840508c3f823dcdc6751d",
      "59695e3fd7c74c9cb6459761b866d3ba",
      "ce007c8d17f240a3be8e76d9c856b0f1",
      "76dbafea2aed4f71971ce850515c6870",
      "4c3177581cf04a3f9e9ef8d2ca60e6a2",
      "92be4e36916c42428a5d7db2c7de7e64",
      "0abbc7ff8b9645e295fa09e93ca92f92",
      "4b9cdbe263ff440fb6690618b2755d00",
      "178df14fc2224cd88a8971fae1cd6b6f",
      "5bd44f95541c4c44a342f607e8467c49",
      "327b25af14ef42ca95895d82066551f4",
      "3c1f692b18d64738b779080e229eb915",
      "02e8fe6d83b64df69e9daefb58c0fa72",
      "4b661bb67340489f9d2d6a3862f7e800",
      "5ee64c0349ce44d681674c52f209bae5",
      "7147ff80ae034f7f926d33e33ac347a0",
      "963d4bcc1a5e44e7bbd48bc9ee2f561a",
      "bab0b6799c0b479fb80237066b5c35fe",
      "9e2e8063e40c46dd92b4e4217fd4e22d",
      "dced80e26c3946b69f5e6f538cfccd2e",
      "8056e6ea564644f497a2809be1d77570",
      "ac3ac1da9c584554864a74ae9047cf28",
      "2e019d6cd05c44fc914ec102a87bc208",
      "ac40b263a8a04f0497ca5e023623da7e",
      "5314bdc7a7224b7a9d9bb1ad056e8af5",
      "db7a56a242b34f14b0eae0e031a84e71",
      "d4c0625121ca473d85d300768322660e",
      "c3c2461eff974a2e8cc8e436b334fb0b",
      "3523ead45f9143f3ac344babca4472a0",
      "0f5c0f17c4474931a9592eaab28aec63",
      "55c137860d7a4269abcbe2ac18bd0fa7",
      "ba8f9203c68741a5a8d3f4a1a62667d3",
      "c9aee1a6090a4c9d9defbc004c982bd3",
      "5e4bc81ed4d0495f84d2a85edab6744a",
      "78be5911cb17463184ccb6bf8e69faeb",
      "69c968b6f8454d5fb747eb105886974d",
      "ef48386d38054104a3117ccfcc60cd1a",
      "9231ede4fefb4303a3ade916c64f382c",
      "abd1f56a9d53431db3d89491c1e2adce",
      "ede25fc50dd941c2a6c7bf62ca4f9c54",
      "40a9b786f3fb4a0987697c633d2a31bc",
      "fff0b30324f3467495af249ddfc0bd2f",
      "dc528deed4ef41489d506bf42fc74047",
      "8bce274b0e2449ee804c48f665bed11b",
      "d964f0b41ae34c3099f14dbf4be5f6f5",
      "4ca1f53b1d504b8a83f138c8864b9323",
      "629245cccbad44de8d926dd6134d5658",
      "aea00b7f2c8f41d0a6f5cf31ea72ed22",
      "1f22f347cf7a48acb1353b4116666013",
      "2b6e1bb32c444b65a4b8ef23b7f95ce1",
      "46c134a58e554e8d8a36659329c918b1",
      "04e0881397c44c38838d8e1483bc768d",
      "17af0774b84641e5bd4c411d827401c8",
      "86d5665bacfe4a50b2c54460736b24ad",
      "d0e39bbb957f4d05bf130788e03504c3",
      "5d152bf0b6e8478282a4f3e86f33cb89",
      "551b10f34e0b464aa326b3a77948e1e3",
      "22d08d61a636457fb8d15b17c61be4de",
      "52fb56250b57412788144556ab33c604",
      "47de5b7e77c24bc0a93037d8f27215d2",
      "8f712f93f3d2412d807859f8dbe65dfe",
      "f6160f5239ca4913bc9dfe2f324f930f",
      "de92c33b74284fb5ba2bd410dbe8d541",
      "c47f293691734b0ba8eb881abf9a7f7b",
      "e7dd9a40cd5e46e691e107e14c2bfbfb",
      "34938ae011cd49f090af49ea46ce2f9b",
      "be60bdef622c44519e9ec60d56ed7f72",
      "7fc26c21cbc042fb96a9d12f8b4b730a"
     ]
    },
    "executionInfo": {
     "elapsed": 2276595,
     "status": "ok",
     "timestamp": 1743754232761,
     "user": {
      "displayName": "yu Wu",
      "userId": "12692660435918028293"
     },
     "user_tz": -60
    },
    "id": "2Nu_CTO_ttTa",
    "outputId": "4d0f1dda-1499-40fa-fb80-3d9ebb6be030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fine-tuning and evaluating model: bert-base-uncased =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01770e86bc4e4bacb15efaafc978cc21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a594eaeb5d47adae05d42c281e5d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cadcc09789024ccc933770105277cf38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b1ebaa8096430a907a7befae899550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746142a0a07243499ce94b6a751a3df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6192' max='6192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6192/6192 06:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.064600</td>\n",
       "      <td>1.008048</td>\n",
       "      <td>0.640417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>1.231042</td>\n",
       "      <td>0.673370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.323400</td>\n",
       "      <td>1.723662</td>\n",
       "      <td>0.674824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Performance for bert-base-uncased ===\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         NEUTRAL       0.72      0.71      0.71      2017\n",
      "STRONGLYNEGATIVE       0.24      0.18      0.20        28\n",
      "STRONGLYPOSITIVE       0.31      0.29      0.30        76\n",
      "  WEAKLYNEGATIVE       0.52      0.51      0.51       440\n",
      "  WEAKLYPOSITIVE       0.69      0.70      0.70      1566\n",
      "\n",
      "        accuracy                           0.67      4127\n",
      "       macro avg       0.49      0.48      0.49      4127\n",
      "    weighted avg       0.67      0.67      0.67      4127\n",
      "\n",
      "Accuracy: 0.67482432759874\n",
      "\n",
      "===== Fine-tuning and evaluating model: roberta-base =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73103fb64ffe47e4897f4769b9617aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11797871578f48a587d81b52846301e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e8069ad4584130bb9964966f7ddb00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559c6c0ef96c4eb990e022e6dec7d42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154142b376cb4463b9f1503f021267da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244e1b284c2c4a15af92c2b8f4649364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6192' max='6192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6192/6192 06:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.061900</td>\n",
       "      <td>1.103679</td>\n",
       "      <td>0.639448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.884700</td>\n",
       "      <td>1.021320</td>\n",
       "      <td>0.659074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.613300</td>\n",
       "      <td>1.133411</td>\n",
       "      <td>0.670705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Performance for roberta-base ===\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         NEUTRAL       0.75      0.65      0.70      2017\n",
      "STRONGLYNEGATIVE       0.37      0.25      0.30        28\n",
      "STRONGLYPOSITIVE       0.29      0.45      0.35        76\n",
      "  WEAKLYNEGATIVE       0.49      0.62      0.55       440\n",
      "  WEAKLYPOSITIVE       0.67      0.74      0.70      1566\n",
      "\n",
      "        accuracy                           0.67      4127\n",
      "       macro avg       0.52      0.54      0.52      4127\n",
      "    weighted avg       0.68      0.67      0.67      4127\n",
      "\n",
      "Accuracy: 0.6707051126726435\n",
      "\n",
      "===== Fine-tuning and evaluating model: distilbert-base-uncased =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1d8c447b5f43a292e14f19d4a05469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286b0bd95e25451aae808b734377de63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e5772334ac42b09f47511c7197003e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10fd91c206114b10b531f9989bc742a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d90799ee274fd8a831afcda9a990ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6192' max='6192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6192/6192 03:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.072500</td>\n",
       "      <td>1.076863</td>\n",
       "      <td>0.632905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.771900</td>\n",
       "      <td>1.122435</td>\n",
       "      <td>0.661255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>1.515739</td>\n",
       "      <td>0.664405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Performance for distilbert-base-uncased ===\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         NEUTRAL       0.71      0.69      0.70      2017\n",
      "STRONGLYNEGATIVE       0.19      0.11      0.14        28\n",
      "STRONGLYPOSITIVE       0.32      0.36      0.34        76\n",
      "  WEAKLYNEGATIVE       0.48      0.48      0.48       440\n",
      "  WEAKLYPOSITIVE       0.68      0.71      0.69      1566\n",
      "\n",
      "        accuracy                           0.66      4127\n",
      "       macro avg       0.48      0.47      0.47      4127\n",
      "    weighted avg       0.66      0.66      0.66      4127\n",
      "\n",
      "Accuracy: 0.6644051369033196\n",
      "\n",
      "===== Fine-tuning and evaluating model: xlnet-base-cased =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d005fe1d3ed43edad5a23ed14331352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c42c86ec8fe4e498440f39b3bd9d4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2164c1434ec54c908d2b6287287616a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ce430b51434c0f8958697b3bd944f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6192' max='6192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6192/6192 07:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.250800</td>\n",
       "      <td>1.308497</td>\n",
       "      <td>0.513690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.135000</td>\n",
       "      <td>1.098060</td>\n",
       "      <td>0.629028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.796300</td>\n",
       "      <td>1.116230</td>\n",
       "      <td>0.652774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41dff0dea714422eaba36e8bab860b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/467M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Performance for xlnet-base-cased ===\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         NEUTRAL       0.72      0.66      0.69      2017\n",
      "STRONGLYNEGATIVE       0.54      0.25      0.34        28\n",
      "STRONGLYPOSITIVE       0.22      0.37      0.28        76\n",
      "  WEAKLYNEGATIVE       0.49      0.57      0.52       440\n",
      "  WEAKLYPOSITIVE       0.66      0.69      0.68      1566\n",
      "\n",
      "        accuracy                           0.65      4127\n",
      "       macro avg       0.53      0.51      0.50      4127\n",
      "    weighted avg       0.66      0.65      0.66      4127\n",
      "\n",
      "Accuracy: 0.6527744124061061\n",
      "\n",
      "===== Fine-tuning and evaluating model: google/electra-base-generator =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf710c17590940c781229eccfd68c9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef7214b441444b9b72ed4ab2358d638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441e97450f59438ab04d410c34994b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae46f9606454cb0a1600d73000f047b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8174b0f99efe4e9dbc551a41d5bbcb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/135M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-generator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6192' max='6192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6192/6192 04:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.110500</td>\n",
       "      <td>1.071633</td>\n",
       "      <td>0.590986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.992300</td>\n",
       "      <td>0.980860</td>\n",
       "      <td>0.650351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.662800</td>\n",
       "      <td>1.056624</td>\n",
       "      <td>0.656409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97ec685d7694283b299ce25334c3164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/135M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Performance for google/electra-base-generator ===\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         NEUTRAL       0.72      0.66      0.69      2017\n",
      "STRONGLYNEGATIVE       0.47      0.29      0.36        28\n",
      "STRONGLYPOSITIVE       0.27      0.33      0.29        76\n",
      "  WEAKLYNEGATIVE       0.46      0.57      0.51       440\n",
      "  WEAKLYPOSITIVE       0.67      0.70      0.69      1566\n",
      "\n",
      "        accuracy                           0.66      4127\n",
      "       macro avg       0.52      0.51      0.51      4127\n",
      "    weighted avg       0.67      0.66      0.66      4127\n",
      "\n",
      "Accuracy: 0.6564090138114853\n",
      "\n",
      "===== Fine-tuning and evaluating model: vinai/bertweet-base =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce007c8d17f240a3be8e76d9c856b0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/558 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b661bb67340489f9d2d6a3862f7e800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5314bdc7a7224b7a9d9bb1ad056e8af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c968b6f8454d5fb747eb105886974d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629245cccbad44de8d926dd6134d5658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6192' max='6192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6192/6192 06:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.018700</td>\n",
       "      <td>1.036478</td>\n",
       "      <td>0.628544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.991500</td>\n",
       "      <td>0.952301</td>\n",
       "      <td>0.669009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.480100</td>\n",
       "      <td>1.154225</td>\n",
       "      <td>0.675794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d08d61a636457fb8d15b17c61be4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Performance for vinai/bertweet-base ===\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         NEUTRAL       0.75      0.65      0.70      2017\n",
      "STRONGLYNEGATIVE       0.33      0.36      0.34        28\n",
      "STRONGLYPOSITIVE       0.37      0.43      0.40        76\n",
      "  WEAKLYNEGATIVE       0.49      0.57      0.53       440\n",
      "  WEAKLYPOSITIVE       0.68      0.75      0.71      1566\n",
      "\n",
      "        accuracy                           0.68      4127\n",
      "       macro avg       0.52      0.55      0.54      4127\n",
      "    weighted avg       0.69      0.68      0.68      4127\n",
      "\n",
      "Accuracy: 0.6757935546401744\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"  # Disable wandb\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dataset Splitting, Label Encoding, and Evaluation Metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "\n",
    "# Includes various pretrained models and utilities from Hugging Face Transformers\n",
    "from transformers import (\n",
    "    BertTokenizer, BertForSequenceClassification,\n",
    "    RobertaTokenizer, RobertaForSequenceClassification,\n",
    "    DistilBertTokenizer, DistilBertForSequenceClassification,\n",
    "    XLNetTokenizer, XLNetForSequenceClassification,\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer\n",
    ")\n",
    "# Neural network submodules in PyTorch\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============== 1. Data Loading and Cleaning ==============\n",
    "df = pd.read_csv(\n",
    "    \"SemEval2017-task4-dev.subtask-CE.english.INPUT.txt\",\n",
    "    sep='\\t',\n",
    "    header=None,\n",
    "    names=['id', 'topic', 'label_num', 'tweet_raw'],\n",
    ")\n",
    "\n",
    "# Mapping Between Numeric and String Labels\n",
    "label_map = {\n",
    "    -2: \"STRONGLYNEGATIVE\",\n",
    "    -1: \"WEAKLYNEGATIVE\",\n",
    "     0: \"NEUTRAL\",\n",
    "     1: \"WEAKLYPOSITIVE\",\n",
    "     2: \"STRONGLYPOSITIVE\"\n",
    "}\n",
    "df['label'] = df['label_num'].map(label_map)\n",
    "\n",
    "# To ensure fairness and comparability, the data cleaning procedures applied to the BERT family of models\n",
    "# are kept consistent with those used for the RNN, BiLSTM, and CNN models\n",
    "def basic_text_cleaning(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#\", \"\", text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9(),!?\\'`]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip() # Replace multiple spaces with a single space and strip leading/trailing whitespace\n",
    "    return text\n",
    "\n",
    "df['tweet'] = df['tweet_raw'].astype(str).apply(basic_text_cleaning) # Perform type conversion\n",
    "\n",
    "# Concatenate the topic and tweet into a single input sequence for BERT\n",
    "df['input_text'] = df.apply(lambda row: f\"[TOPIC] {row['topic']} [SEP] {row['tweet']}\", axis=1)\n",
    "\n",
    "# ============== 2. Augmentation Using a Sentiment Lexicon ==============\n",
    "senti_lexicon = {\n",
    "    \"love\": 2, \"like\": 1, \"good\": 1, \"hate\": -2, \"bad\": -1, \"horrible\": -2\n",
    "}\n",
    "def lexicon_score(sentence):\n",
    "    words = sentence.lower().split() # Convert sentences to lowercase and compare word by word\n",
    "    score = 0\n",
    "    for w in words:\n",
    "        if w in senti_lexicon:\n",
    "            score += senti_lexicon[w]\n",
    "    return score\n",
    "\n",
    "df['lexicon_score'] = df['tweet'].apply(lexicon_score) # Store the scores in df['lexicon_score']\n",
    "\n",
    "# ============== 3. Data splitting and handling of class imbalance ==============\n",
    "le = LabelEncoder()\n",
    "df['label_id'] = le.fit_transform(df['label'])  # Convert to the range 0–4\n",
    "\n",
    "# Use stratified sampling to ensure similar label distributions in the training and test sets\n",
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df['label_id'] # Set a random seed to ensure reproducibility\n",
    ")\n",
    "\n",
    "# Compute class weights for use in weighted cross-entropy loss\n",
    "# Assign higher weights to rare classes\n",
    "train_labels_array = train_df['label_id'].to_numpy()\n",
    "class_counts = Counter(train_labels_array)\n",
    "num_samples = len(train_labels_array)\n",
    "num_classes = len(class_counts)\n",
    "weights = [num_samples / (num_classes * class_counts[i]) for i in range(num_classes)]\n",
    "class_weights = torch.tensor(weights, dtype=torch.float)\n",
    "\n",
    "# ============== 4. Construct the Dataset ==============\n",
    "# Use the tokenizer to tokenize the input text, convert it to token IDs,\n",
    "# truncate or pad to max_len, and generate the corresponding attention_mask\n",
    "class BERTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len # Maximum length per text\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):  # Tokenize the input text, convert it to token IDs, and apply truncation or padding to max_len\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True, # Automatically add [CLS] and [SEP] tokens\n",
    "            max_length=self.max_len, # Set the maximum sequence length\n",
    "            padding='max_length',  # Pad sequences shorter than max_len\n",
    "            truncation=True,     # Truncate sequences that exceed max_len\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].squeeze()  # Return as a dictionary\n",
    "        attention_mask = encoding['attention_mask'].squeeze() # Remove extra dimensions\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,      # Token ID\n",
    "            'attention_mask': attention_mask, # Attention mask\n",
    "            'labels': torch.tensor(label, dtype=torch.long) # Convert labels to LongTensor type\n",
    "        }\n",
    "\n",
    "# Convert to Python lists for constructing a custom Dataset\n",
    "train_texts = train_df['input_text'].tolist()\n",
    "train_labels = train_df['label_id'].tolist()\n",
    "test_texts = test_df['input_text'].tolist()\n",
    "test_labels = test_df['label_id'].tolist()\n",
    "\n",
    "# ============== 5. Custom Trainer with Weighted Cross-Entropy Loss ==============\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Because additional arguments (e.g., num_items_in_batch) may be passed to Trainer during execution,\n",
    "        **kwargs is included to prevent errors\n",
    "        \"\"\"\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"}) # Perform forward propagation\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Using class_weights（Alternatively, use the ordinary loss_fct = nn.CrossEntropyLoss()）\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=class_weights.to(logits.device)) # Compute the loss\n",
    "        loss = loss_fct(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# ============== 6. Training Configuration (TrainingArguments) ==============\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./checkpoints',\n",
    "    num_train_epochs=3,       # Train for 3 epochs\n",
    "    per_device_train_batch_size=8, # Set the batch size to 8 per GPU/CPU during training and validation\n",
    "    per_device_eval_batch_size=8,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,  # Log every 50 steps\n",
    "    do_eval=True,\n",
    "    report_to=\"none\",  # Turn off wandb logging\n",
    ")\n",
    "\n",
    "# ============== 7. Train each model sequentially and output its test performance separately ==============\n",
    "# Save both the model and tokenizer for later use in ensemble evaluation\n",
    "model_names = [\n",
    "    \"bert-base-uncased\",\n",
    "    \"roberta-base\",\n",
    "    \"distilbert-base-uncased\",\n",
    "    \"xlnet-base-cased\",\n",
    "    \"google/electra-base-generator\",\n",
    "    # The most suitable BERT model for recognizing Twitter tweets\n",
    "    \"vinai/bertweet-base\"\n",
    "]\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "train_dataset = BERTDataset(train_texts, train_labels, None, max_len=128)\n",
    "test_dataset  = BERTDataset(test_texts,  test_labels,  None, max_len=128)\n",
    "\n",
    "all_models = []\n",
    "all_tokenizers = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f\"\\n===== Fine-tuning and evaluating model: {model_name} =====\")\n",
    "\n",
    "    # 1) Load tokenizer & model\n",
    "    # BERTweet follows the same architecture as RoBERTa and can be used via AutoTokenizer and AutoModel\n",
    "    if \"roberta\" in model_name.lower():\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "        model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=5)\n",
    "    elif \"distilbert\" in model_name.lower():\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "        model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=5)\n",
    "    elif \"xlnet\" in model_name.lower():\n",
    "        tokenizer = XLNetTokenizer.from_pretrained(model_name)\n",
    "        model = XLNetForSequenceClassification.from_pretrained(model_name, num_labels=5)\n",
    "    elif \"electra\" in model_name.lower():\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5)\n",
    "    elif \"bertweet\" in model_name.lower():\n",
    "        # BERTweet is typically based on the RoBERTa architecture\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5)\n",
    "    else:\n",
    "        # Default BERT\n",
    "        tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        model = BertForSequenceClassification.from_pretrained(model_name, num_labels=5)\n",
    "\n",
    "    # 2) Update the tokenizer used in the dataset\n",
    "    train_dataset.tokenizer = tokenizer\n",
    "    test_dataset.tokenizer  = tokenizer\n",
    "\n",
    "    # 3) Define the Trainer\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,      # Loaded pretrained model\n",
    "        args=training_args,  # Training Parameters\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # 4) Training\n",
    "    trainer.train()\n",
    "\n",
    "    # 5) Test set prediction with a single model\n",
    "    pred_output = trainer.predict(test_dataset)\n",
    "    predictions = pred_output.predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    test_labels_true = test_df['label_id'].tolist()\n",
    "\n",
    "    # 6) Display evaluation for the single model\n",
    "    print(f\"=== Test Performance for {model_name} ===\")\n",
    "    print(classification_report(test_labels_true, preds, target_names=le.classes_))\n",
    "    acc = accuracy_score(test_labels_true, preds)\n",
    "    print(\"Accuracy:\", acc)\n",
    "\n",
    "    # 7) Save the model and tokenizer to a list for later use in ensemble\n",
    "    all_models.append(model)\n",
    "    all_tokenizers.append(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 258124,
     "status": "ok",
     "timestamp": 1743754490907,
     "user": {
      "displayName": "yu Wu",
      "userId": "12692660435918028293"
     },
     "user_tz": -60
    },
    "id": "wG4v9Dz0twms",
    "outputId": "b4feec15-269a-4226-9c6e-92db8702f269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Ensemble (logits average) on Test Set =====\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         NEUTRAL       0.74      0.70      0.72      2017\n",
      "STRONGLYNEGATIVE       0.31      0.14      0.20        28\n",
      "STRONGLYPOSITIVE       0.33      0.36      0.34        76\n",
      "  WEAKLYNEGATIVE       0.52      0.56      0.54       440\n",
      "  WEAKLYPOSITIVE       0.70      0.74      0.72      1566\n",
      "\n",
      "        accuracy                           0.69      4127\n",
      "       macro avg       0.52      0.50      0.50      4127\n",
      "    weighted avg       0.69      0.69      0.69      4127\n",
      "\n",
      "Ensemble Accuracy: 0.6903319602616913\n"
     ]
    }
   ],
   "source": [
    "# ============== 8. Perform ensemble by averaging logits across models ==============\n",
    "def predict_ensemble(texts, max_len=128):\n",
    "    # Prefer using GPU acceleration\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    for m in all_models:\n",
    "        m.to(device)\n",
    "        m.eval() # Set the model to evaluation mode\n",
    "\n",
    "# Initialize an empty list to store predictions for all input texts\n",
    "    preds_ens = []\n",
    "    for text in texts:\n",
    "        logits_sum = None\n",
    "        for tkn, mdl in zip(all_tokenizers, all_models):\n",
    "            inputs = tkn(\n",
    "                text,\n",
    "                return_tensors='pt',\n",
    "                max_length=max_len,\n",
    "                truncation=True,\n",
    "                padding='max_length'\n",
    "            )\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            with torch.no_grad():\n",
    "                out = mdl(**inputs)  # Forward propagation\n",
    "                logits = out.logits.detach().cpu().numpy()\n",
    "            if logits_sum is None:  # Initialize with the logits from the first model\n",
    "                logits_sum = logits\n",
    "            else:\n",
    "                logits_sum += logits\n",
    "\n",
    "        # Compute the mean\n",
    "        ensemble_logits = logits_sum / len(all_models)\n",
    "        # argmax\n",
    "        pred_label_id = np.argmax(ensemble_logits, axis=1)[0]\n",
    "        preds_ens.append(pred_label_id)\n",
    "\n",
    "    return preds_ens\n",
    "\n",
    "print(\"\\n===== Ensemble (logits average) on Test Set =====\")\n",
    "test_preds_ens = predict_ensemble(test_texts)\n",
    "test_labels_true = test_df['label_id'].tolist()\n",
    "print(classification_report(test_labels_true, test_preds_ens, target_names=le.classes_))\n",
    "acc_ens = accuracy_score(test_labels_true, test_preds_ens)\n",
    "print(\"Ensemble Accuracy:\", acc_ens)\n",
    "\n",
    "# Convert predictions from numeric labels back to text\n",
    "# ensemble_pred_labels_str = le.inverse_transform(test_preds_ens)\n",
    "# print(\"Sample ensemble predictions:\", ensemble_pred_labels_str[:10])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNn2P11Y0lZGtKxpwgjsQn5",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
